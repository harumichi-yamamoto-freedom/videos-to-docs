import { useCallback } from 'react';
import { VideoConverter } from '@/lib/ffmpeg';
import { GeminiClient } from '@/lib/gemini';
import { FileWithPrompts, FileProcessingStatus, DebugErrorMode } from '@/types/processing';
import { convertVideoToAudioSegments, resumeVideoConversion } from '@/lib/videoConversionService';
import { createLogger } from '@/lib/logger';

interface UseProcessingWorkflowProps {
    converterRef: React.MutableRefObject<VideoConverter | null>;
    geminiClientRef: React.MutableRefObject<GeminiClient | null>;
    audioConversionQueueRef: React.MutableRefObject<boolean>;
    ffmpegLoaded: boolean;
    setFfmpegLoaded: (loaded: boolean) => void;
    setProcessingStatuses: React.Dispatch<React.SetStateAction<FileProcessingStatus[]>>;
    processTranscription: (file: FileWithPrompts, fileIndex: number, audioBlob: Blob, bitrate: string, sampleRate: number) => Promise<void>;
    processTranscriptionResume: (file: FileWithPrompts, fileIndex: number, audioBlob: Blob, completedPromptIds: string[], bitrate: string, sampleRate: number) => Promise<void>;
    debugErrorMode: DebugErrorMode;
    // ğŸ¬ å‹•ç”»ã‚’ç›´æ¥é€ä¿¡ã™ã‚‹ãƒ•ãƒ©ã‚°ï¼ˆè©¦é¨“çš„ï¼‰
    sendVideoDirectly?: boolean;
}

const processingWorkflowLogger = createLogger('useProcessingWorkflow');

export const useProcessingWorkflow = ({
    converterRef,
    geminiClientRef,
    audioConversionQueueRef,
    ffmpegLoaded,
    setFfmpegLoaded,
    setProcessingStatuses,
    processTranscription,
    processTranscriptionResume,
    debugErrorMode,
    sendVideoDirectly = false, // ğŸ¬ å‹•ç”»ã‚’ç›´æ¥é€ä¿¡ã™ã‚‹ãƒ•ãƒ©ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯falseï¼‰
}: UseProcessingWorkflowProps) => {

    // ãƒ¡ã‚¤ãƒ³å‡¦ç†
    const handleStartProcessing = useCallback(async (
        selectedFiles: FileWithPrompts[],
        bitrate: string,
        sampleRate: number
    ) => {
        if (selectedFiles.length === 0) return;

        // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        const hasPrompts = selectedFiles.every(file => file.selectedPromptIds.length > 0);
        if (!hasPrompts) {
            alert('ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«æœ€ä½1ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„');
            return;
        }

        // åˆæœŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¨­å®š
        const initialStatuses: FileProcessingStatus[] = selectedFiles.map(fileWithPrompts => ({
            fileName: fileWithPrompts.file.name,
            status: 'waiting',
            phase: 'waiting',
            audioConversionProgress: 0,
            totalTranscriptions: fileWithPrompts.selectedPromptIds.length,
            transcriptionCount: 0,
            completedPromptIds: [],
            segmentDuration: 30,
            segments: [],
            completedSegmentIndices: [],
        }));
        setProcessingStatuses(initialStatuses);

        // VideoConverterã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        if (!converterRef.current) {
            converterRef.current = new VideoConverter();
        }

        // GeminiClientã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        if (!geminiClientRef.current) {
            geminiClientRef.current = new GeminiClient();
        }

        try {
            // FFmpegã‚’åˆå›ã®ã¿ãƒ­ãƒ¼ãƒ‰
            if (!ffmpegLoaded) {
                await converterRef.current.load();
                setFfmpegLoaded(true);
            }

            // ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†: éŸ³å£°å¤‰æ›ï¼ˆç›´åˆ—ï¼‰â†’ å¤‰æ›å®Œäº†æ¬¡ç¬¬ã€æ–‡æ›¸ç”Ÿæˆã‚’ä¸¦åˆ—é–‹å§‹
            const transcriptionPromises: Promise<void>[] = [];

            for (let i = 0; i < selectedFiles.length; i++) {
                const file = selectedFiles[i];

                // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                const isAudioFile = file.file.type.startsWith('audio/') ||
                    file.file.name.toLowerCase().match(/\.(mp3|wav|m4a|aac|ogg|flac)$/);

                if (isAudioFile) {
                    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼šéŸ³å£°å¤‰æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç›´æ¥æ–‡æ›¸ç”Ÿæˆã¸
                    setProcessingStatuses(prev =>
                        prev.map((status, idx) =>
                            idx === i
                                ? { ...status, convertedAudioBlob: file.file as Blob }
                                : status
                        )
                    );
                    const transcriptionPromise = processTranscription(file, i, file.file as Blob, bitrate, sampleRate);
                    transcriptionPromises.push(transcriptionPromise);
                } else {
                    // å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                    // ğŸ¬ å‹•ç”»ã‚’ç›´æ¥é€ä¿¡ã™ã‚‹å ´åˆ
                    if (sendVideoDirectly) {
                        processingWorkflowLogger.info('å‹•ç”»ã‚’ç›´æ¥é€ä¿¡ãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†', { fileName: file.file.name });

                        // éŸ³å£°å¤‰æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å‹•ç”»ã‚’ç›´æ¥ä½¿ç”¨
                        setProcessingStatuses(prev =>
                            prev.map((status, idx) =>
                                idx === i
                                    ? { ...status, status: 'converting', phase: 'direct_video_send', audioConversionProgress: 100 }
                                    : status
                            )
                        );

                        // å‹•ç”»Blobã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã‹ã‚‰æ–‡æ›¸ç”Ÿæˆã‚’ä¸¦åˆ—ã§é–‹å§‹
                        setProcessingStatuses(prev =>
                            prev.map((status, idx) =>
                                idx === i
                                    ? { ...status, convertedAudioBlob: file.file as Blob }
                                    : status
                            )
                        );

                        // processTranscriptionã«å‹•ç”»Blobã‚’æ¸¡ã™ï¼ˆå†…éƒ¨ã§GeminiClient.transcribeVideoã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ã‚ã‚Šï¼‰
                        const transcriptionPromise = processTranscription(file, i, file.file as Blob, bitrate, sampleRate);
                        transcriptionPromises.push(transcriptionPromise);
                    } else {
                        // é€šå¸¸ã®éŸ³å£°å¤‰æ›å‡¦ç†ï¼šåŒºé–“å¤‰æ›ãŒå¿…è¦ï¼ˆç›´åˆ—å‡¦ç†ï¼‰
                        audioConversionQueueRef.current = true;

                        try {
                            // å‹•ç”»ã®é•·ã•ã‚’å–å¾—ã¨åŒºé–“å¤‰æ›
                            setProcessingStatuses(prev =>
                                prev.map((status, idx) =>
                                    idx === i
                                        ? { ...status, status: 'converting', phase: 'audio_conversion', audioConversionProgress: 0 }
                                        : status
                                )
                            );

                            const audioBlob = await convertVideoToAudioSegments(
                                file,
                                i,
                                converterRef.current!,
                                bitrate,
                                sampleRate,
                                debugErrorMode,
                                setProcessingStatuses
                            );

                            if (audioBlob) {
                                // éŸ³å£°å¤‰æ›ãŒæˆåŠŸã—ãŸã‚‰ã€Blobã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã™ãã«æ–‡æ›¸ç”Ÿæˆã‚’ä¸¦åˆ—ã§é–‹å§‹
                                setProcessingStatuses(prev =>
                                    prev.map((status, idx) =>
                                        idx === i
                                            ? { ...status, convertedAudioBlob: audioBlob }
                                            : status
                                    )
                                );
                                const transcriptionPromise = processTranscription(file, i, audioBlob, bitrate, sampleRate);
                                transcriptionPromises.push(transcriptionPromise);
                            }
                        } finally {
                            // éŸ³å£°å¤‰æ›å‡¦ç†å®Œäº†
                            audioConversionQueueRef.current = false;
                        }
                    }
                }
            }

            // ã™ã¹ã¦ã®æ–‡æ›¸ç”ŸæˆãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            await Promise.all(transcriptionPromises);
        } catch (error) {
            processingWorkflowLogger.error('ä¸€æ‹¬å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ', error);
            alert('å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ' + (error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'));
        }
    }, [
        converterRef,
        geminiClientRef,
        audioConversionQueueRef,
        ffmpegLoaded,
        setFfmpegLoaded,
        setProcessingStatuses,
        processTranscription,
        debugErrorMode,
        sendVideoDirectly // ğŸ¬ å‹•ç”»ç›´æ¥é€ä¿¡ãƒ•ãƒ©ã‚°
    ]);

    // å†é–‹å‡¦ç†
    const handleResumeFile = useCallback(async (
        fileIndex: number,
        selectedFiles: FileWithPrompts[],
        processingStatuses: FileProcessingStatus[],
        bitrate: string,
        sampleRate: number
    ) => {
        processingWorkflowLogger.info('å†é–‹å‡¦ç†ã‚’é–‹å§‹', { fileIndex });

        const file = selectedFiles[fileIndex];
        const status = processingStatuses[fileIndex];

        if (!file || !status) {
            processingWorkflowLogger.error(
                'å†é–‹å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“',
                undefined,
                {
                    fileIndex,
                    selectedFiles: selectedFiles.length,
                    processingStatuses: processingStatuses.length,
                }
            );
            return;
        }

        if (status.isResuming) {
            processingWorkflowLogger.warn('å†é–‹å‡¦ç†ã¯æ—¢ã«é€²è¡Œä¸­ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—', { fileIndex });
            return;
        }

        processingWorkflowLogger.info('å†é–‹å¯¾è±¡ã®ç¾åœ¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', {
            fileIndex,
            fileName: status.fileName,
            phase: status.phase,
            status: status.status,
            hasError: Boolean(status.error),
            failedPhase: status.failedPhase,
            segments: status.segments.length,
            completedSegments: status.completedSegmentIndices.length,
            hasAudio: Boolean(status.convertedAudioBlob),
            completedPrompts: status.completedPromptIds.length,
            totalPrompts: status.totalTranscriptions,
        });

        setProcessingStatuses(prev =>
            prev.map((s, idx) =>
                idx === fileIndex
                    ? { ...s, isResuming: true, error: undefined }
                    : s
            )
        );

        try {
            processingWorkflowLogger.info('å†é–‹å‡¦ç†ã«å¿…è¦ãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æº–å‚™', { fileIndex });
            if (!converterRef.current) {
                converterRef.current = new VideoConverter();
                processingWorkflowLogger.info('VideoConverter ã‚’æ–°è¦ä½œæˆ', { fileIndex });
            }

            if (!geminiClientRef.current) {
                geminiClientRef.current = new GeminiClient();
                processingWorkflowLogger.info('GeminiClient ã‚’æ–°è¦ä½œæˆ', { fileIndex });
            }

            if (!ffmpegLoaded) {
                processingWorkflowLogger.info('FFmpeg ã‚’èª­ã¿è¾¼ã¿', { fileIndex });
                await converterRef.current.load();
                setFfmpegLoaded(true);
                processingWorkflowLogger.info('FFmpeg ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†', { fileIndex });
            }

            processingWorkflowLogger.info('å†é–‹å‡¦ç†ã®åˆ†å²ã‚’åˆ¤å®š', { fileIndex });

            // éŸ³å£°å¤‰æ›æ¸ˆã¿ã®å ´åˆã¯ã€æ–‡æ›¸ç”Ÿæˆã®ã¿ã‚’å®Ÿè¡Œ
            if (status.convertedAudioBlob) {
                processingWorkflowLogger.info('éŸ³å£°å¤‰æ›æ¸ˆã¿ã®ãŸã‚æ–‡æ›¸ç”Ÿæˆã®ã¿ã‚’å†é–‹', { fileIndex });
                await processTranscriptionResume(file, fileIndex, status.convertedAudioBlob, status.completedPromptIds, bitrate, sampleRate);
            } else {
                processingWorkflowLogger.info('éŸ³å£°æœªå¤‰æ›ã®ãŸã‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š', { fileIndex });

                const isAudioFile = file.file.type.startsWith('audio/') ||
                    file.file.name.toLowerCase().match(/\.(mp3|wav|m4a|aac|ogg|flac)$/);

                if (isAudioFile) {
                    processingWorkflowLogger.info('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ãŸãŸã‚å¤‰æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—', { fileIndex });
                    setProcessingStatuses(prev =>
                        prev.map((s, idx) =>
                            idx === fileIndex
                                ? { ...s, convertedAudioBlob: file.file as Blob }
                                : s
                        )
                    );
                    await processTranscriptionResume(file, fileIndex, file.file as Blob, status.completedPromptIds, bitrate, sampleRate);
                } else {
                    processingWorkflowLogger.info('å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ãŸãŸã‚éŸ³å£°å¤‰æ›ã‚’å†é–‹', { fileIndex });
                    setProcessingStatuses(prev =>
                        prev.map((s, idx) =>
                            idx === fileIndex
                                ? { ...s, phase: 'waiting' }
                                : s
                        )
                    );

                    processingWorkflowLogger.info('éŸ³å£°å¤‰æ›ã‚­ãƒ¥ãƒ¼ã®ç©ºãã‚’ç¢ºèª', { fileIndex });
                    let waitCount = 0;
                    while (audioConversionQueueRef.current) {
                        waitCount++;
                        await new Promise(resolve => setTimeout(resolve, 100));
                    }
                    if (waitCount > 0) {
                        processingWorkflowLogger.info('éŸ³å£°å¤‰æ›ã‚­ãƒ¥ãƒ¼ã®å¾…æ©ŸãŒå®Œäº†', {
                            fileIndex,
                            waitedMs: waitCount * 100,
                        });
                    } else {
                        processingWorkflowLogger.info('éŸ³å£°å¤‰æ›ã‚­ãƒ¥ãƒ¼ã«å³åº§ã«å‚åŠ ', { fileIndex });
                    }

                    audioConversionQueueRef.current = true;
                    processingWorkflowLogger.info('éŸ³å£°å¤‰æ›ã‚­ãƒ¥ãƒ¼ã‚’ãƒ­ãƒƒã‚¯', { fileIndex });

                    try {
                        processingWorkflowLogger.info('éŸ³å£°å¤‰æ›ãƒ•ã‚§ãƒ¼ã‚ºã¸é·ç§»', { fileIndex });
                        setProcessingStatuses(prev =>
                            prev.map((s, idx) =>
                                idx === fileIndex
                                    ? { ...s, status: 'converting', phase: 'audio_conversion' }
                                    : s
                            )
                        );

                        const audioBlob = await resumeVideoConversion(
                            file,
                            fileIndex,
                            status,
                            converterRef.current!,
                            bitrate,
                            sampleRate,
                            debugErrorMode,
                            setProcessingStatuses
                        );

                        if (audioBlob) {
                            setProcessingStatuses(prev =>
                                prev.map((s, idx) =>
                                    idx === fileIndex
                                        ? { ...s, convertedAudioBlob: audioBlob }
                                        : s
                                )
                            );
                            await processTranscriptionResume(file, fileIndex, audioBlob, status.completedPromptIds, bitrate, sampleRate);
                        }
                    } finally {
                        processingWorkflowLogger.info('éŸ³å£°å¤‰æ›ã‚­ãƒ¥ãƒ¼ã®ãƒ­ãƒƒã‚¯ã‚’è§£é™¤', { fileIndex });
                        audioConversionQueueRef.current = false;
                    }
                }
            }
        } catch (error) {
            processingWorkflowLogger.error('å†é–‹å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ', error, { fileIndex });
            setProcessingStatuses(prev =>
                prev.map((s, idx) =>
                    idx === fileIndex
                        ? {
                            ...s,
                            status: 'error',
                            error: error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼',
                            isResuming: false
                        }
                        : s
                )
            );
        } finally {
            processingWorkflowLogger.info('å†é–‹å‡¦ç†ã®çµ‚äº†å‡¦ç†ã‚’å®Ÿè¡Œ', { fileIndex });
            setProcessingStatuses(prev =>
                prev.map((s, idx) =>
                    idx === fileIndex && s.isResuming
                        ? { ...s, isResuming: false }
                        : s
                )
            );
            processingWorkflowLogger.info('isResuming ãƒ•ãƒ©ã‚°ã‚’è§£é™¤', { fileIndex });
        }
    }, [
        converterRef,
        geminiClientRef,
        audioConversionQueueRef,
        ffmpegLoaded,
        setFfmpegLoaded,
        setProcessingStatuses,
        processTranscriptionResume,
        debugErrorMode
    ]);

    return {
        handleStartProcessing,
        handleResumeFile,
    };
};


