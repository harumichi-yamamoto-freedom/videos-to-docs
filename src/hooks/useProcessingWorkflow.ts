import { useCallback } from 'react';
import { VideoConverter } from '@/lib/ffmpeg';
import { GeminiClient } from '@/lib/gemini';
import { FileWithPrompts, FileProcessingStatus, DebugErrorMode } from '@/types/processing';
import { convertVideoToAudioSegments, resumeVideoConversion } from '@/lib/videoConversionService';

interface UseProcessingWorkflowProps {
    converterRef: React.MutableRefObject<VideoConverter | null>;
    geminiClientRef: React.MutableRefObject<GeminiClient | null>;
    audioConversionQueueRef: React.MutableRefObject<boolean>;
    ffmpegLoaded: boolean;
    setFfmpegLoaded: (loaded: boolean) => void;
    setProcessingStatuses: React.Dispatch<React.SetStateAction<FileProcessingStatus[]>>;
    processTranscription: (file: FileWithPrompts, fileIndex: number, audioBlob: Blob, bitrate: string, sampleRate: number) => Promise<void>;
    processTranscriptionResume: (file: FileWithPrompts, fileIndex: number, audioBlob: Blob, completedPromptIds: string[], bitrate: string, sampleRate: number) => Promise<void>;
    debugErrorMode: DebugErrorMode;
}

export const useProcessingWorkflow = ({
    converterRef,
    geminiClientRef,
    audioConversionQueueRef,
    ffmpegLoaded,
    setFfmpegLoaded,
    setProcessingStatuses,
    processTranscription,
    processTranscriptionResume,
    debugErrorMode,
}: UseProcessingWorkflowProps) => {

    // ãƒ¡ã‚¤ãƒ³å‡¦ç†
    const handleStartProcessing = useCallback(async (
        selectedFiles: FileWithPrompts[],
        bitrate: string,
        sampleRate: number
    ) => {
        if (selectedFiles.length === 0) return;

        // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        const hasPrompts = selectedFiles.every(file => file.selectedPromptIds.length > 0);
        if (!hasPrompts) {
            alert('ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«æœ€ä½1ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„');
            return;
        }

        // åˆæœŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¨­å®š
        const initialStatuses: FileProcessingStatus[] = selectedFiles.map(fileWithPrompts => ({
            fileName: fileWithPrompts.file.name,
            status: 'waiting',
            phase: 'waiting',
            audioConversionProgress: 0,
            totalTranscriptions: fileWithPrompts.selectedPromptIds.length,
            transcriptionCount: 0,
            completedPromptIds: [],
            segmentDuration: 30,
            segments: [],
            completedSegmentIndices: [],
        }));
        setProcessingStatuses(initialStatuses);

        // VideoConverterã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        if (!converterRef.current) {
            converterRef.current = new VideoConverter();
        }

        // GeminiClientã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        if (!geminiClientRef.current) {
            geminiClientRef.current = new GeminiClient();
        }

        try {
            // FFmpegã‚’åˆå›ã®ã¿ãƒ­ãƒ¼ãƒ‰
            if (!ffmpegLoaded) {
                await converterRef.current.load();
                setFfmpegLoaded(true);
            }

            // ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†: éŸ³å£°å¤‰æ›ï¼ˆç›´åˆ—ï¼‰â†’ å¤‰æ›å®Œäº†æ¬¡ç¬¬ã€æ–‡æ›¸ç”Ÿæˆã‚’ä¸¦åˆ—é–‹å§‹
            const transcriptionPromises: Promise<void>[] = [];

            for (let i = 0; i < selectedFiles.length; i++) {
                const file = selectedFiles[i];

                // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                const isAudioFile = file.file.type.startsWith('audio/') ||
                    file.file.name.toLowerCase().match(/\.(mp3|wav|m4a|aac|ogg|flac)$/);

                if (isAudioFile) {
                    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼šéŸ³å£°å¤‰æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç›´æ¥æ–‡æ›¸ç”Ÿæˆã¸
                    setProcessingStatuses(prev =>
                        prev.map((status, idx) =>
                            idx === i
                                ? { ...status, convertedAudioBlob: file.file as Blob }
                                : status
                        )
                    );
                    const transcriptionPromise = processTranscription(file, i, file.file as Blob, bitrate, sampleRate);
                    transcriptionPromises.push(transcriptionPromise);
                } else {
                    // å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼šåŒºé–“å¤‰æ›ãŒå¿…è¦ï¼ˆç›´åˆ—å‡¦ç†ï¼‰
                    audioConversionQueueRef.current = true;

                    try {
                        // å‹•ç”»ã®é•·ã•ã‚’å–å¾—ã¨åŒºé–“å¤‰æ›
                        setProcessingStatuses(prev =>
                            prev.map((status, idx) =>
                                idx === i
                                    ? { ...status, status: 'converting', phase: 'audio_conversion', audioConversionProgress: 0 }
                                    : status
                            )
                        );

                        const audioBlob = await convertVideoToAudioSegments(
                            file,
                            i,
                            converterRef.current!,
                            bitrate,
                            sampleRate,
                            debugErrorMode,
                            setProcessingStatuses
                        );

                        if (audioBlob) {
                            // éŸ³å£°å¤‰æ›ãŒæˆåŠŸã—ãŸã‚‰ã€Blobã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ã™ãã«æ–‡æ›¸ç”Ÿæˆã‚’ä¸¦åˆ—ã§é–‹å§‹
                            setProcessingStatuses(prev =>
                                prev.map((status, idx) =>
                                    idx === i
                                        ? { ...status, convertedAudioBlob: audioBlob }
                                        : status
                                )
                            );
                            const transcriptionPromise = processTranscription(file, i, audioBlob, bitrate, sampleRate);
                            transcriptionPromises.push(transcriptionPromise);
                        }
                    } finally {
                        // éŸ³å£°å¤‰æ›å‡¦ç†å®Œäº†
                        audioConversionQueueRef.current = false;
                    }
                }
            }

            // ã™ã¹ã¦ã®æ–‡æ›¸ç”ŸæˆãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
            await Promise.all(transcriptionPromises);
        } catch (error) {
            console.error('å‡¦ç†ã‚¨ãƒ©ãƒ¼:', error);
            alert('å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ' + (error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'));
        }
    }, [
        converterRef,
        geminiClientRef,
        audioConversionQueueRef,
        ffmpegLoaded,
        setFfmpegLoaded,
        setProcessingStatuses,
        processTranscription,
        debugErrorMode
    ]);

    // å†é–‹å‡¦ç†
    const handleResumeFile = useCallback(async (
        fileIndex: number,
        selectedFiles: FileWithPrompts[],
        processingStatuses: FileProcessingStatus[],
        bitrate: string,
        sampleRate: number
    ) => {
        console.log('='.repeat(80));
        console.log('ğŸ”„ [å†é–‹] å‡¦ç†é–‹å§‹ - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹:', fileIndex);
        console.log('='.repeat(80));

        const file = selectedFiles[fileIndex];
        const status = processingStatuses[fileIndex];

        if (!file || !status) {
            console.error('âŒ [å†é–‹] ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“');
            console.error('  - selectedFiles.length:', selectedFiles.length);
            console.error('  - processingStatuses.length:', processingStatuses.length);
            console.error('  - fileIndex:', fileIndex);
            return;
        }

        if (status.isResuming) {
            console.log('â¸ï¸ [å†é–‹] ã‚¹ã‚­ãƒƒãƒ—: æ—¢ã«å†é–‹å‡¦ç†ä¸­ã§ã™');
            return;
        }

        console.log('ğŸ“Š [å†é–‹] ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:');
        console.log('  - ãƒ•ã‚¡ã‚¤ãƒ«å:', status.fileName);
        console.log('  - ãƒ•ã‚§ãƒ¼ã‚º:', status.phase);
        console.log('  - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:', status.status);
        console.log('  - ã‚¨ãƒ©ãƒ¼:', status.error);
        console.log('  - å¤±æ•—ãƒ•ã‚§ãƒ¼ã‚º:', status.failedPhase);
        console.log('  - åŒºé–“æ•°:', status.segments.length);
        console.log('  - å®Œäº†åŒºé–“æ•°:', status.completedSegmentIndices.length);
        console.log('  - éŸ³å£°å¤‰æ›æ¸ˆã¿:', !!status.convertedAudioBlob);
        console.log('  - å®Œäº†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°:', status.completedPromptIds.length, '/', status.totalTranscriptions);

        console.log('ğŸš© [å†é–‹] ãƒ•ãƒ©ã‚°è¨­å®š: isResuming = true');
        setProcessingStatuses(prev =>
            prev.map((s, idx) =>
                idx === fileIndex
                    ? { ...s, isResuming: true, error: undefined }
                    : s
            )
        );

        try {
            console.log('ğŸ”§ [å†é–‹] ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç¢ºèªä¸­...');
            if (!converterRef.current) {
                console.log('  - VideoConverteræ–°è¦ä½œæˆ');
                converterRef.current = new VideoConverter();
            } else {
                console.log('  - VideoConverteræ—¢å­˜');
            }

            if (!geminiClientRef.current) {
                console.log('  - GeminiClientæ–°è¦ä½œæˆ');
                geminiClientRef.current = new GeminiClient();
            } else {
                console.log('  - GeminiClientæ—¢å­˜');
            }

            if (!ffmpegLoaded) {
                console.log('â³ [å†é–‹] FFmpegèª­ã¿è¾¼ã¿ä¸­...');
                await converterRef.current.load();
                setFfmpegLoaded(true);
                console.log('âœ… [å†é–‹] FFmpegèª­ã¿è¾¼ã¿å®Œäº†');
            } else {
                console.log('âœ… [å†é–‹] FFmpegæ—¢ã«èª­ã¿è¾¼ã¿æ¸ˆã¿');
            }

            console.log('ğŸ”€ [å†é–‹] å‡¦ç†åˆ†å²åˆ¤å®š...');

            // éŸ³å£°å¤‰æ›æ¸ˆã¿ã®å ´åˆã¯ã€æ–‡æ›¸ç”Ÿæˆã®ã¿ã‚’å®Ÿè¡Œ
            if (status.convertedAudioBlob) {
                console.log('ğŸ“ [å†é–‹] åˆ†å²A: éŸ³å£°å¤‰æ›æ¸ˆã¿ â†’ æ–‡æ›¸ç”Ÿæˆã®ã¿å®Ÿè¡Œ');
                await processTranscriptionResume(file, fileIndex, status.convertedAudioBlob, status.completedPromptIds, bitrate, sampleRate);
            } else {
                console.log('ğŸµ [å†é–‹] åˆ†å²B: éŸ³å£°æœªå¤‰æ› â†’ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¤å®š');

                const isAudioFile = file.file.type.startsWith('audio/') ||
                    file.file.name.toLowerCase().match(/\.(mp3|wav|m4a|aac|ogg|flac)$/);

                if (isAudioFile) {
                    console.log('ğŸ¼ [å†é–‹] åˆ†å²B-1: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º â†’ éŸ³å£°å¤‰æ›ã‚¹ã‚­ãƒƒãƒ—');
                    setProcessingStatuses(prev =>
                        prev.map((s, idx) =>
                            idx === fileIndex
                                ? { ...s, convertedAudioBlob: file.file as Blob }
                                : s
                        )
                    );
                    await processTranscriptionResume(file, fileIndex, file.file as Blob, status.completedPromptIds, bitrate, sampleRate);
                } else {
                    console.log('ğŸ¬ [å†é–‹] åˆ†å²B-2: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º â†’ éŸ³å£°å¤‰æ›ãŒå¿…è¦');

                    console.log('â¸ï¸ [å†é–‹] å¾…æ©Ÿä¸­çŠ¶æ…‹ã«è¨­å®š');
                    setProcessingStatuses(prev =>
                        prev.map((s, idx) =>
                            idx === fileIndex
                                ? { ...s, phase: 'waiting' }
                                : s
                        )
                    );

                    console.log('ğŸ”’ [å†é–‹] éŸ³å£°å¤‰æ›ã‚­ãƒ¥ãƒ¼ç¢ºèªä¸­...');
                    let waitCount = 0;
                    while (audioConversionQueueRef.current) {
                        waitCount++;
                        if (waitCount % 10 === 0) {
                            console.log(`  - å¾…æ©Ÿä¸­... (${waitCount * 100}msçµŒé)`);
                        }
                        await new Promise(resolve => setTimeout(resolve, 100));
                    }
                    if (waitCount > 0) {
                        console.log(`âœ… [å†é–‹] å¾…æ©Ÿå®Œäº† (${waitCount * 100}ms)`);
                    } else {
                        console.log('âœ… [å†é–‹] ã‚­ãƒ¥ãƒ¼ç©ºã - å³åº§ã«é–‹å§‹');
                    }

                    console.log('ğŸ”“ [å†é–‹] ã‚­ãƒ¥ãƒ¼ã‚’ãƒ­ãƒƒã‚¯');
                    audioConversionQueueRef.current = true;

                    try {
                        console.log('ğŸ¯ [å†é–‹] éŸ³å£°å¤‰æ›ãƒ•ã‚§ãƒ¼ã‚ºã«ç§»è¡Œ');
                        setProcessingStatuses(prev =>
                            prev.map((s, idx) =>
                                idx === fileIndex
                                    ? { ...s, status: 'converting', phase: 'audio_conversion' }
                                    : s
                            )
                        );

                        const audioBlob = await resumeVideoConversion(
                            file,
                            fileIndex,
                            status,
                            converterRef.current!,
                            bitrate,
                            sampleRate,
                            debugErrorMode,
                            setProcessingStatuses
                        );

                        if (audioBlob) {
                            setProcessingStatuses(prev =>
                                prev.map((s, idx) =>
                                    idx === fileIndex
                                        ? { ...s, convertedAudioBlob: audioBlob }
                                        : s
                                )
                            );
                            await processTranscriptionResume(file, fileIndex, audioBlob, status.completedPromptIds, bitrate, sampleRate);
                        }
                    } finally {
                        console.log('ğŸ”“ [å†é–‹] ã‚­ãƒ¥ãƒ¼ã®ãƒ­ãƒƒã‚¯è§£é™¤');
                        audioConversionQueueRef.current = false;
                    }
                }
            }
        } catch (error) {
            console.error('='.repeat(80));
            console.error('âŒ [å†é–‹] ã‚­ãƒ£ãƒƒãƒã•ã‚ŒãŸã‚¨ãƒ©ãƒ¼:');
            console.error('  - ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:', error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼');
            console.error('  - ã‚¨ãƒ©ãƒ¼ã‚¹ã‚¿ãƒƒã‚¯:', error instanceof Error ? error.stack : 'ã‚¹ã‚¿ãƒƒã‚¯ãªã—');
            console.error('='.repeat(80));
            setProcessingStatuses(prev =>
                prev.map((s, idx) =>
                    idx === fileIndex
                        ? {
                            ...s,
                            status: 'error',
                            error: error instanceof Error ? error.message : 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼',
                            isResuming: false
                        }
                        : s
                )
            );
        } finally {
            console.log('ğŸ [å†é–‹] finally ãƒ–ãƒ­ãƒƒã‚¯å®Ÿè¡Œ');
            console.log('  - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹:', fileIndex);
            setProcessingStatuses(prev =>
                prev.map((s, idx) =>
                    idx === fileIndex && s.isResuming
                        ? { ...s, isResuming: false }
                        : s
                )
            );
            console.log('âœ¨ [å†é–‹] å‡¦ç†å®Œäº† - isResumingãƒ•ãƒ©ã‚°ã‚¯ãƒªã‚¢');
            console.log('='.repeat(80));
        }
    }, [
        converterRef,
        geminiClientRef,
        audioConversionQueueRef,
        ffmpegLoaded,
        setFfmpegLoaded,
        setProcessingStatuses,
        processTranscriptionResume,
        debugErrorMode
    ]);

    return {
        handleStartProcessing,
        handleResumeFile,
    };
};


